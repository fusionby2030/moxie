{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b8eb650-6912-4735-adad-a5bd147b60d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data stuffs\n",
    "import pickle \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib \n",
    "import os, sys\n",
    "from moxie.data.utils_ import load_data, standardize, de_standardize, normalize_profiles\n",
    "\n",
    "\n",
    "# Make it look pretty\n",
    "from tqdm.notebook import tqdm  \n",
    "\n",
    "# ML Stuff\n",
    "from scipy.stats import truncnorm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f712a7a-459c-4785-bf97-94c636ecc972",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = load_data(dataset_choice='SANDBOX_NO_VARIATIONS', file_loc='../../../moxie/data/processed/pedestal_profiles_ML_READY_ak_5052022_uncerts_mask.pickle')\n",
    "(train_X, train_y, train_mask, train_radii, train_real_space_radii, train_ids, train_uncert), (val_X, val_y, val_mask, val_radii, val_real_space_radii, val_ids, val_uncert), (test_X, test_y, test_mask, test_radii, test_real_space_radii, test_ids, test_uncert) = train_data, val_data, test_data\n",
    "# profiles, mps, masks, psis, rmids, trainids, uncerts\n",
    "with open('../../data/raw/new_elm_timings_catch.pickle', 'rb') as file: \n",
    "    JET_ELM_TIMINGS = pickle.load(file) \n",
    "\n",
    "machine_param_order = ['Q95', 'RGEO', 'CR0', 'VOLM', 'TRIU', 'TRIL', 'ELON', 'POHM', 'IPLA', 'BVAC', 'NBI', 'ICRH', 'ELER']\n",
    "\n",
    "def unique(sequence):\n",
    "    seen = set()\n",
    "    return [x for x in sequence if not (x in seen or seen.add(x))]\n",
    "\n",
    "train_pulse_order = [int(x.split('/')[0]) for x in train_ids]\n",
    "train_pulses_ordered_set = unique(train_pulse_order)\n",
    "train_pulse_idxs = [[index for index in range(len(train_pulse_order)) if train_pulse_order[index] == pulse] for pulse in train_pulses_ordered_set]\n",
    "\n",
    "val_pulse_order = [int(x.split('/')[0]) for x in val_ids]\n",
    "val_pulses_ordered_set = unique(val_pulse_order)\n",
    "val_pulse_idxs = [[index for index in range(len(val_pulse_order)) if val_pulse_order[index] == pulse] for pulse in val_pulses_ordered_set]\n",
    "\n",
    "test_pulse_order = [int(x.split('/')[0]) for x in test_ids]\n",
    "test_pulses_ordered_set = unique(test_pulse_order)\n",
    "test_pulse_idxs = [[index for index in range(len(test_pulse_order)) if test_pulse_order[index] == pulse] for pulse in test_pulses_ordered_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fdfdf2e2-c400-4d2d-838d-26ecf37c667f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714b26d2baa4442591ec449d32a9c896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing elm timings\n",
      "Slices outside of ELM Windows found by Frassinetti:  4518\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eb5d37cdc5c4760836e728d512ee1d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd6b63a9cfe449739b544b3e09c5aad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing elm timings\n",
      "Slices outside of ELM Windows found by Frassinetti:  1241\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc8b0954de43455b8c208486500a99b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1190144f466040d5b90c3e9c7f88527f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing elm timings\n",
      "Slices outside of ELM Windows found by Frassinetti:  561\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ace1c7a2ca1419ab1cb8448d0450064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def calculate_elm_percent(time_last_elm, time_next_elm, hrts_time): \n",
    "    return (hrts_time - time_last_elm) / (time_next_elm - time_last_elm)\n",
    "\n",
    "def find_elm_timings_for_set(dataset, pulse_indexes, pulse_numbers, elm_dict): \n",
    "    \"\"\"\n",
    "    This will return np array of elm percentages per slice. \n",
    "    i.e., it is of length num_slice in the set\n",
    "    \"\"\"\n",
    "    _, _, _, _, _, setids, _ = dataset\n",
    "    setids = np.array(setids)\n",
    "    elm_percentages = []\n",
    "    lost_slices = 0\n",
    "    iterator = tqdm(enumerate(zip(pulse_indexes, pulse_numbers)))\n",
    "    print('doing elm timings')\n",
    "    for n, (indexes, number) in iterator:\n",
    "        \n",
    "        iterator.set_description(str(number))\n",
    "        try: \n",
    "            pulse_elm_timings_frass = np.array(elm_dict[number])\n",
    "        except KeyError as e:\n",
    "            pulse_elm_percentages = [np.nan]*len(indexes)\n",
    "            lost_slices += len(indexes)\n",
    "        else:\n",
    "            pulse_elm_percentages = []\n",
    "            hrts_timings = [float(time_slice.split('/')[1]) for time_slice in setids[indexes]]\n",
    "            for time in hrts_timings: \n",
    "                diff = pulse_elm_timings_frass - time\n",
    "                try:\n",
    "                    time_last_elm = pulse_elm_timings_frass[diff < 0][-1]\n",
    "                    time_next_elm = pulse_elm_timings_frass[diff > 0][0]\n",
    "                except IndexError as e:\n",
    "                    # print('Outside of ELM timings', time, pulse_elm_timings_frass)\n",
    "                    slice_elm_percent = np.nan\n",
    "                    lost_slices += 1\n",
    "                else: \n",
    "                    slice_elm_percent = calculate_elm_percent(time_next_elm, time_last_elm, time)\n",
    "                pulse_elm_percentages.append(slice_elm_percent)\n",
    "        elm_percentages.extend(pulse_elm_percentages)\n",
    "    print('Slices outside of ELM Windows found by Frassinetti: ', lost_slices)\n",
    "    \n",
    "    return np.array(elm_percentages)\n",
    "\n",
    "\n",
    "\n",
    "def make_new_set(dataset, pulse_indexes, pulse_numbers, elm_dict): \n",
    "    \"\"\"\n",
    "    Now we go about kicking out all of the slices that fell outside the elm window range given by T17-05. \n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    \n",
    "    pulse_indexes: List[List[int]]\n",
    "        For each pulse, a list of indexes of the profiles/mps/rmids/etc corresponding to that pulse \n",
    "        This needs to be rewritten in terms of what is available for ELM timings \n",
    "    pulse_numbers: List[int]\n",
    "        List of pulse numbers in the order of the pulse indexes\n",
    "        \n",
    "    \"\"\"\n",
    "    set_elm_percentages = find_elm_timings_for_set(dataset, pulse_indexes, pulse_numbers, elm_dict)\n",
    "    profiles, mps, masks, psis, rmids, setids, uncerts = dataset\n",
    "    \n",
    "    # The number of slices that have elm percentages\n",
    "    num_has_elm_percentage = len(set_elm_percentages) - np.isnan(set_elm_percentages).sum()\n",
    "\n",
    "    new_pulse_numbers = pulse_numbers.copy()\n",
    "    new_indexes = pulse_indexes.copy()\n",
    "    # new_mps, new_masks, new_psis, new_rmids, new_trainids, new_uncerts = \n",
    "    \n",
    "    iterator = tqdm(enumerate(zip(pulse_indexes, pulse_numbers)))\n",
    "    # go through the indexes and pop those that are correspond to \n",
    "    for n, (number) in iterator:\n",
    "        iterator.set_description(str(number))\n",
    "        elm_slices_for_pulse = set_elm_percentages[pulse_indexes[n]]\n",
    "        non_nan_idx = np.invert(np.isnan(elm_slices_for_pulse))\n",
    "        new_indexes[n] = np.array(new_indexes[n])[non_nan_idx].tolist()\n",
    "        \n",
    "        \n",
    "    return new_indexes, set_elm_percentages\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "train_new_pulse_ids, train_elm_percentages = make_new_set(train_data, train_pulse_idxs, train_pulses_ordered_set, JET_ELM_TIMINGS)\n",
    "val_new_pulse_ids, val_elm_percentages = make_new_set(val_data, val_pulse_idxs, val_pulses_ordered_set, JET_ELM_TIMINGS)\n",
    "test_new_pulse_ids, test_elm_percentages = make_new_set(test_data, test_pulse_idxs, test_pulses_ordered_set, JET_ELM_TIMINGS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "013d844e-23a1-48b0-853c-f8fa686ec482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4518, 22885)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(train_elm_percentages).sum(), len(train_elm_percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddeceafd-1d33-40d9-b061-9ecae22f77de",
   "metadata": {},
   "outputs": [],
   "source": [
    "elm_timing_dict = {'train': {'pulse_idx': train_new_pulse_ids, 'elm_percentages': train_elm_percentages}, \n",
    "                   'val': {'pulse_idx': val_new_pulse_ids, 'elm_percentages': val_elm_percentages}, \n",
    "                   'test': {'pulse_idx': test_new_pulse_ids, 'elm_percentages': test_elm_percentages}}\n",
    "with open('../../data/processed/new_elm_timings_idxs.pickle', 'wb') as file: \n",
    "    pickle.dump(elm_timing_dict, file) \n",
    "\n",
    "# for p in range(5, 100):\n",
    "#     assert len(train_new_pulse_ids[p]) == len(train_pulse_idxs[p]), p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ff15af-f551-4ca8-bb72-c1fb2bab89d1",
   "metadata": {},
   "source": [
    "Collect neseps for each slice in train-val-test, and store and save as smaller subset. \n",
    "\n",
    "```\n",
    "    dict_supervsied = {'train': {'mps': np.array((13, N)), 'neseps': np.array(N))}, \n",
    "                        'val': {'mps': np.array((13, N)), 'neseps': np.array(N))}, \n",
    "                        'test': {'mps': np.array((13, N)), 'neseps': np.array(N))}}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab20758f-e0b0-4d6f-933e-c9df5e90437d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_neseps_in_set(set_ids, set_profiles, set_uncerts, set_masks, set_mps, set_timings, set_shot_numbers_by_slice): \n",
    "    iterator = tqdm(range(len(set_ids)))\n",
    "    \n",
    "    nesep_means_by_pulse = []\n",
    "    neseps_means = []\n",
    "    mps_means = []\n",
    "    for k in iterator: \n",
    "        slice_loc_in_set = set_ids[k]\n",
    "         \n",
    "        pulse_number = np.array(set_shot_numbers_by_slice)[set_ids[k]][0]\n",
    "        \n",
    "        sample_profiles, sample_uncerts, sample_masks, sample_mps, sample_timings = set_profiles[slice_loc_in_set], set_uncerts[slice_loc_in_set], set_masks[slice_loc_in_set], set_mps[slice_loc_in_set], set_timings[slice_loc_in_set]\n",
    "        pulse_neseps = calculate_nesep_for_pulse(sample_profiles, sample_uncerts, sample_masks, lbound_n = 0, ubound_n = 0.5e21, lbound_t=0, ubound_t=2000)\n",
    "        nesep_means_by_pulse.extend(pulse_neseps)\n",
    "        \n",
    "        neseps_means.append(pulse_neseps.mean())\n",
    "        mps_means.append(sample_mps.mean(0))\n",
    "        iterator.set_description_str(str(pulse_number))        \n",
    "        break \n",
    "        \n",
    "    return np.array(nesep_means_by_pulse), np.array(neseps_means), np.array(mps_means)\n",
    "\n",
    "\n",
    "def calculate_nesep_for_pulse(both_profiles, both_uncertanties, integer_masks, lbound_n, ubound_n, lbound_t, ubound_t, conditional_prediction=False):\n",
    "    \"\"\"\n",
    "    This will return the neseps predicted for each time slice in the pulse. \n",
    "    \"\"\"\n",
    "    \n",
    "    pulse_neseps = np.zeros(len(both_profiles))\n",
    "    pulse_teseps = np.zeros(len(both_profiles))\n",
    "    if conditional_prediction: \n",
    "        integer_masks = np.ones_like(integer_masks, dtype=bool)\n",
    "        both_uncertanties = np.ones_like(both_uncertanties, dtype=bool)*200\n",
    "    \n",
    "    for n, (both_profiles_slice, both_uncertanties_slice, mask_int_slice) in enumerate(zip(both_profiles, both_uncertanties, integer_masks)):\n",
    "        bool_mask = mask_int_slice > 0\n",
    "        slice_ne, slice_te = both_profiles_slice[0, :][bool_mask], both_profiles_slice[1, :][bool_mask]\n",
    "        slice_ne_uncert, slice_te_uncert = both_uncertanties_slice[0, :][bool_mask], both_uncertanties_slice[1, :][bool_mask]\n",
    "        \n",
    "        tes_gaussians = np.array([np.linspace(truncnorm.ppf(0.0001, (lbound_t - mu) / var, (ubound_t - mu) / var, mu, var), \n",
    "                                     truncnorm.ppf(0.9999, (lbound_t - mu) / var, (ubound_t - mu) / var, mu, var), 10000)\n",
    "                        for mu, var in zip(slice_te, slice_te_uncert)])\n",
    "        \n",
    "        separatrix_loc = np.logical_and(tes_gaussians > 90, tes_gaussians < 110)\n",
    "        tesep_in_separatrix = tes_gaussians[separatrix_loc]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        nes_gaussians = np.array([np.linspace(truncnorm.ppf(0.1, (lbound_n - mu) / var, (ubound_n - mu) / var, mu, var), \n",
    "                                     truncnorm.ppf(0.9, (lbound_n - mu) / var, (ubound_n - mu) / var, mu, var), 10000)\n",
    "                        for mu, var in zip(slice_ne, slice_ne_uncert)])\n",
    "\n",
    "        nes_in_separatrix = nes_gaussians[separatrix_loc]\n",
    "        if len(nes_in_separatrix) == 0: \n",
    "            print(slice_ne, slice_te, slice_ne_uncert, slice_te_uncert)\n",
    "        slice_nesep = np.mean(nes_in_separatrix)\n",
    "        slice_tesep = np.mean(tesep_in_separatrix)\n",
    "        pulse_neseps[n] = slice_nesep\n",
    "        pulse_teseps[n] = slice_tesep\n",
    "    \n",
    "    return pulse_neseps\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09322c15-9b6f-4984-bdb6-5ae5360d7950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67dba59da339457fa090f2e531e68454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/533 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ade31c77f63a469c80d48fdd7e6f159d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07757c75aeb342a6ba782a50fd8411fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/77 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_neseps, train_neseps_mean, train_mps_mean = calculate_neseps_in_set(train_pulse_idxs, train_X, train_uncert, train_mask, train_y, train_pulse_order, train_ids)\n",
    "val_neseps, val_neseps_mean, val_mps_mean = calculate_neseps_in_set(val_pulse_idxs, val_X, val_uncert, val_mask, val_y, val_pulse_order, val_ids)\n",
    "test_neseps, test_neseps_mean, test_mps_mean = calculate_neseps_in_set(test_pulse_idxs, test_X, test_uncert, test_mask, test_y, test_pulse_order, test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "112b1ae9-6da3-4350-97ac-93047380e4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22885 22885\n",
      "533 (533, 13)\n"
     ]
    }
   ],
   "source": [
    "print(len(train_neseps), len(train_y))\n",
    "print(len(train_neseps_mean), train_mps_mean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98406756-70bb-41ba-96ea-4fb8702e00ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "63204512-fba3-4837-88bd-d2c96e5bdf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_dict = {'train': {'mps': train_y, 'neseps': train_neseps, 'mps_pulse': train_mps_mean, 'neseps_pulse': train_neseps_mean}, \n",
    "                    'val': {'mps': val_y, 'neseps': val_neseps, 'mps_pulse': val_mps_mean, 'neseps_pulse': val_neseps_mean}, \n",
    "                    'test': {'mps': test_y, 'neseps': test_neseps, 'mps_pulse': test_mps_mean, 'neseps_pulse': test_neseps_mean}, \n",
    "                  'MP_ORDER': machine_param_order}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d41bf2fb-a2fc-4548-9a1c-727c73ec84ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "PERSONAL_DATA_DIR_PROC = '/home/kitadam/ENR_Sven/moxie/data/processed/'\n",
    "# with open(PERSONAL_DATA_DIR_PROC + 'supervised_set.pickle', 'wb') as file:\n",
    "#     pickle.dump(supervised_dict, file)\n",
    "with open(PERSONAL_DATA_DIR_PROC + 'supervised_set.pickle', 'rb') as file:\n",
    "    supervised_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8096b356-3f36-40f7-b826-009ef62660fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645199dc-8f3f-495b-bdeb-d425f0089cd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a6b891-0d2a-447c-ae92-4946a119d027",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
