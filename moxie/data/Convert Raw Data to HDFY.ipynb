{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c205a3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b20914f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5481f6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_shots_with_T_raw_p3.pickle', 'rb') as file:\n",
    "    pulse_dicts = pickle.load(file)\n",
    "    \n",
    "\"\"\"\n",
    "with open('all_shots_with_T_raw_p3.pickle', 'wb') as file:\n",
    "    pickle.dump(pulse_dicts, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "204eed83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ccfc8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cols_efit = ['Q95', 'RGEO', 'CR0', 'VOLM', 'TRIU', 'TRIL', 'XIP', 'ELON', 'POHM']\n",
    "input_cols_scal = ['BT']\n",
    "input_cols_gash = ['ELER']\n",
    "input_cols_nbi = ['P_NBI']\n",
    "input_cols_icrh = ['P_ICRH']\n",
    "\n",
    "col_time_efit = ['EFIT_T']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0afd1c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88bc698b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('../processed/profile_database.hdf5', 'w')\n",
    "for n, (pulse_id, pulse_data) in enumerate(pulse_dicts.items()):\n",
    "    try :\n",
    "        pulse_grp = f.create_group(pulse_id)\n",
    "\n",
    "        input_grp = pulse_grp.create_group('machine_parameters')\n",
    "        profile_grp = pulse_grp.create_group('profiles')\n",
    "\n",
    "        pulse_input_data = pulse_data['inputs']\n",
    "        pulse_output_data = pulse_data['outputs']\n",
    "\n",
    "        for input_id, input_data in pulse_input_data.items():\n",
    "            if input_id == 'EFIT_T' or input_id ==  'CRO':\n",
    "                continue\n",
    "            individual_grp = input_grp.create_group(input_id)\n",
    "            \n",
    "            if input_id not in input_cols_efit:\n",
    "                input_data, input_time = input_data['values'], input_data['time']\n",
    "            else:\n",
    "                input_time = pulse_input_data['EFIT_T']\n",
    "            \n",
    "            dset_r = individual_grp.create_dataset(\"values\", data=np.array(input_data))\n",
    "            dset_t = individual_grp.create_dataset(\"time\", data=np.array(input_time))\n",
    "            \n",
    "        for out_id, output_data in pulse_output_data.items():\n",
    "            dset_p = profile_grp.create_dataset(out_id, data=output_data)\n",
    "            \n",
    "        \n",
    "    except ValueError as e: \n",
    "        print(e)\n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57b63dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printname(name):\n",
    "    return name\n",
    "\n",
    "i = 0\n",
    "with h5py.File('../processed/profile_database.hdf5', 'r') as file: \n",
    "    # print(file.visit(printname))\n",
    "    \n",
    "    for name in file: \n",
    "        print(name)\n",
    "        for subgroup in file[name]:\n",
    "            print(subgroup)\n",
    "            for index in file[name + '/' + subgroup]:\n",
    "                print(index)\n",
    "                for field in file[name + '/' + subgroup + '/' + index]:\n",
    "                    print(field)\n",
    "        break \n",
    "        # i += 1\n",
    "        # if i == 3: \n",
    "        #     break\n",
    "    # for pulse in file.keys():\n",
    "    #     print(file[pulse + '/machine_parameters'].keys())\n",
    "    #    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e1eb6c",
   "metadata": {},
   "source": [
    "Now we can create the PSI database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "08e0be71",
   "metadata": {},
   "outputs": [],
   "source": [
    "EFIT = ['Q95', 'RGEO', 'CR0', 'VOLM', 'TRIU', 'TRIL', 'XIP', 'ELON', 'POHM']\n",
    "ALL_KEYS = EFIT + ['BT', 'ELER', 'P_NBI', 'P_ICRH', 'NE']\n",
    "def sample_nesep(mean_val, std_val):\n",
    "    return np.random.normal(mean_val, std_val)\n",
    "\n",
    "def sample_input(input_grp, key, t1, t2, nesep):\n",
    "    # for key in list(input_grp.keys()):\n",
    "    if key == 'NE':\n",
    "        return nesep\n",
    "    source = key + '/'\n",
    "    sample_time = input_grp[key + '/time'][:]\n",
    "    sample_values = input_grp[key + '/values'][:]\n",
    "\n",
    "    time_idx = np.logical_and(sample_time > t1, sample_time < t2)\n",
    "    sample = np.mean(sample_values[time_idx])\n",
    "        \n",
    "    return sample\n",
    "\n",
    "def get_ne_and_te_profiles(raw_shot, t1, t2):\n",
    "    sample_ne = raw_shot['profiles/NE'][:]\n",
    "    sample_te = raw_shot['profiles/TE'][:]\n",
    "    sample_time = raw_shot['profiles/time'][:]\n",
    "    sample_radius = raw_shot['profiles/radius'][:]\n",
    "    \n",
    "    profiles_idx = np.logical_and(sample_time > t1, sample_time < t2)\n",
    "    profiles_ne = sample_ne[profiles_idx]\n",
    "    profiles_te = sample_te[profiles_idx]\n",
    "    if len(profiles_ne[0]) != 63:\n",
    "        profiles_ne = np.pad(profiles_ne, ((0, 0), (0, 63 - len(profiles_ne[0]))), 'constant')\n",
    "    if len(profiles_te[0]) != 63:\n",
    "        profiles_te = np.pad(profiles_te, ((0, 0), (0, 63 - len(profiles_te[0]))), 'constant')\n",
    "    \n",
    "    # Returns to numpy arrays of the same shape\n",
    "    return profiles_ne, profiles_te, sample_radius\n",
    "\n",
    "def combine_ne_te(prof_ne, prof_te):\n",
    "    \n",
    "    combined = np.stack([prof_ne, prof_te], axis=1)\n",
    "    # Want a shape of num_slices X 63\n",
    "    return combined\n",
    "\n",
    "def sample_slices(slices, y):\n",
    "    num_windows = len(slices)\n",
    "        \n",
    "    test_size = int(0.2*num_windows)\n",
    "    val_size = int(0.1*num_windows)\n",
    "    \n",
    "    if val_size == 0 or test_size==0:\n",
    "        val_size = 1\n",
    "        test_size = 1\n",
    "        \n",
    "    train_size = num_windows - test_size - val_size\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, train_idx, test_idx =  train_test_split(slices, y, range(len(slices)), test_size=test_size)\n",
    "    X_train, X_val, y_train, y_val, train_idx, val_idx = train_test_split(X_train, y_train, range(len(X_train)), test_size=val_size)\n",
    "    \n",
    "    return X_train, X_test, X_val, y_train, y_test, y_val, train_idx, val_idx, test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c85b60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_pdb = pd.read_csv('pedestal-database.csv')\n",
    "important_info = jet_pdb[['shot', 't1', 't2', 'neseparatrixfromexpdata10^19(m^-3)', 'error_neseparatrixfromexpdata10^19(m^-3)','neseparatrixfromfit10^19(m^-3)',\n",
    " 'error_neseparatrixfromfit10^19(m^-3)','FLAG:HRTSdatavalidated']]\n",
    "final_pulse_list = important_info[(important_info['neseparatrixfromexpdata10^19(m^-3)'] != 0.0) & (important_info['neseparatrixfromexpdata10^19(m^-3)'] != -1.0) &  (important_info['shot'] >= 79000) &  (important_info['FLAG:HRTSdatavalidated'] > 0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d17d4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_str, y_train_str = [], []\n",
    "X_val_str, y_val_str = [], []\n",
    "X_test_str, y_test_str = [], []\n",
    "\n",
    "X_train_both, y_train_both = [], []\n",
    "X_val_both, y_val_both = [], []\n",
    "X_test_both, y_test_both = [], []\n",
    "\n",
    "radius_train_str = []\n",
    "radius_val_str = []\n",
    "radius_test_str = []\n",
    "radius_train_both = []\n",
    "radius_val_both = []\n",
    "radius_test_both = []\n",
    "\n",
    "pulse_list = []\n",
    "with h5py.File('../processed/profile_database.hdf5', 'r+') as f:\n",
    "    try: \n",
    "        grp_datasets = f.create_group(\"processed_datasets\")\n",
    "    except ValueError as e: \n",
    "        grp_datasets = f['processed_datasets']\n",
    "    try: \n",
    "        grp_psi = grp_datasets.create_group(\"PSI22\")\n",
    "    except ValueError as e: \n",
    "        grp_psi = grp_datasets['PSI22']\n",
    "    \n",
    "    try: \n",
    "        grp_strohman = grp_psi.create_group(\"density\")\n",
    "    except ValueError as e: \n",
    "        grp_strohman = grp_psi['density']\n",
    "    try: \n",
    "        grp_both = grp_psi.create_group(\"density_and_temperature\")\n",
    "    except ValueError as e: \n",
    "        grp_both = grp_psi['density_and_temperature']\n",
    "    \n",
    "    try: \n",
    "        grp_str_train = grp_strohman.create_group('train')\n",
    "        grp_str_test = grp_strohman.create_group('test')\n",
    "        grp_str_val = grp_strohman.create_group('valid')\n",
    "\n",
    "        grp_both_train = grp_both.create_group('train')\n",
    "        grp_both_test = grp_both.create_group('test')\n",
    "        grp_both_val = grp_both.create_group('valid')\n",
    "    except: \n",
    "        grp_str_train = grp_strohman['train']\n",
    "        grp_str_test = grp_strohman['test']\n",
    "        grp_str_val = grp_strohman['valid']\n",
    "        grp_both_train = grp_both['train']\n",
    "        grp_both_test = grp_both['test']\n",
    "        grp_both_val = grp_both['valid']\n",
    "\n",
    "    # loop through JET PDB \n",
    "    for index, row in final_pulse_list.iterrows():\n",
    "        shot, t1, t2 = str(int(row['shot'])), row['t1'], row['t2']\n",
    "        nesep, dnesep = row['neseparatrixfromexpdata10^19(m^-3)'], row['error_neseparatrixfromexpdata10^19(m^-3)']\n",
    "        raw_shot = f[shot]\n",
    "        pulse_list.append(shot)\n",
    "        \n",
    "        profiles_ne, profiles_te, radii = get_ne_and_te_profiles(raw_shot, t1, t2)\n",
    "        combined = combine_ne_te(profiles_ne, profiles_te)\n",
    "        other_params = np.array([[sample_input(raw_shot['machine_parameters'], key, t1, t2, nesep) for key in ALL_KEYS] for _ in range(len(profiles_ne))])\n",
    "        \n",
    "        \n",
    "        ne_train, ne_test, ne_valid, ne_y_train, ne_y_test, ne_y_val, train_idx, val_idx, test_idx = sample_slices(profiles_ne, other_params)\n",
    "        \n",
    "        both_train, both_test, both_valid, both_y_train, both_y_test, both_y_val, both_train_idx, both_val_idx, both_test_idx = sample_slices(combined, other_params)\n",
    "        \n",
    "        X_train_str.extend(ne_train)\n",
    "        X_val_str.extend(ne_valid)\n",
    "        X_test_str.extend(ne_test)\n",
    "        y_train_str.extend(ne_y_train)\n",
    "        y_val_str.extend(ne_y_val)\n",
    "        y_test_str.extend(ne_y_test)\n",
    "\n",
    "\n",
    "        X_train_both.extend(both_train)\n",
    "        X_val_both.extend(both_valid)\n",
    "        X_test_both.extend(both_test)\n",
    "        y_train_both.extend(both_y_train)\n",
    "        y_val_both.extend(both_y_val)\n",
    "        y_test_both.extend(both_y_test)\n",
    "        \n",
    "        radius_train_str.extend([radii for _ in range(len(ne_train))])\n",
    "        radius_val_str.extend([radii for _ in range(len(ne_valid))])\n",
    "        radius_test_str.extend([radii for _ in range(len(ne_test))])\n",
    "        radius_train_both.extend([radii for _ in range(len(both_train))])\n",
    "        radius_val_both.extend([radii for _ in range(len(both_valid))])\n",
    "        radius_test_both.extend([radii for _ in range(len(both_test))])\n",
    "    \n",
    "    try: \n",
    "        meta_group = grp_psi.create_group(\"meta\")\n",
    "    except ValueError as e: \n",
    "        meta_group = grp_psi['meta']\n",
    "    pulse_list = np.array(list(set([int(key) for key in pulse_list])))\n",
    "    key_list = np.array([s.encode('utf-8') for s in ALL_KEYS])\n",
    "    meta_pulse = meta_group.create_dataset('pulse_list', data=pulse_list)\n",
    "    meta_y_atrr = meta_group.create_dataset('y_column_names', data=key_list)\n",
    "\n",
    "    print(np.vstack(X_train_str).shape, np.vstack(y_train_str).shape)\n",
    "    print(np.vstack(X_val_str).shape, np.vstack(y_val_str).shape)\n",
    "    print(np.vstack(X_test_str).shape, np.vstack(y_test_str).shape)\n",
    "\n",
    "    print(np.stack(X_train_both).shape, np.stack(y_train_both).shape)\n",
    "    print(np.stack(X_val_both).shape, np.stack(y_val_both).shape)\n",
    "    print(np.stack(X_test_both).shape, np.stack(y_test_both).shape)\n",
    "    dset_X_train_str = grp_str_train.create_dataset(\"X\", data=X_train_str)\n",
    "    dset_y_train_str = grp_str_train.create_dataset(\"y\", data=y_train_str)\n",
    "    dset_r_train_str = grp_str_train.create_dataset(\"radii\", data=radius_train_str)\n",
    "\n",
    "    dset_X_test_str = grp_str_test.create_dataset(\"X\", data=X_test_str)\n",
    "    dset_y_test_str = grp_str_test.create_dataset(\"y\", data=y_test_str)\n",
    "    dset_r_test_str = grp_str_test.create_dataset(\"radii\", data=radius_test_str)\n",
    "\n",
    "    dset_X_val_str = grp_str_val.create_dataset(\"X\", data=X_val_str)\n",
    "    dset_y_val_str = grp_str_val.create_dataset(\"y\", data=y_val_str)\n",
    "    dset_r_val_str = grp_str_val.create_dataset(\"radii\", data=radius_val_str)\n",
    "\n",
    "\n",
    "    dset_X_train_both = grp_both_train.create_dataset(\"X\", data=X_train_both)\n",
    "    dset_y_train_both = grp_both_train.create_dataset(\"y\", data=y_train_both)\n",
    "    dset_r_train_both = grp_both_train.create_dataset(\"radii\", data=radius_train_both)\n",
    "        \n",
    "    dset_X_test_both = grp_both_test.create_dataset(\"X\", data=X_test_both)\n",
    "    dset_y_test_both = grp_both_test.create_dataset(\"y\", data=y_test_both)\n",
    "    dset_r_test_both = grp_both_test.create_dataset(\"radii\", data=radius_test_both)\n",
    "    \n",
    "    dset_X_val_both = grp_both_val.create_dataset(\"X\", data=X_val_both)\n",
    "    dset_y_val_both = grp_both_val.create_dataset(\"y\", data=y_val_both)\n",
    "    dset_r_val_both = grp_both_val.create_dataset(\"radii\", data=radius_val_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58aad25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
