{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8df8de4-b117-4e5a-ab7f-c666406139f5",
   "metadata": {},
   "source": [
    "# Update PSI Dataset\n",
    "\n",
    "Want to include time evolving parameters. \n",
    "\n",
    "\n",
    "## Requirements of Dataset \n",
    "\n",
    "- Some of the pulses should be never before seen in the test set. \n",
    "- The rest are split \n",
    "- Pulses and time windows come from JET PDB (flat top H-mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "08042280-18f6-4011-aed8-445ac9e485b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20a03fa8-78a3-48a0-864b-127d314d8388",
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_pdb = pd.read_csv('/home/adam/ENR_Sven/moxie/data/raw/pedestal-database.csv')\n",
    "important_info = jet_pdb[['shot', 't1', 't2', 'neseparatrixfromexpdata10^19(m^-3)', 'error_neseparatrixfromexpdata10^19(m^-3)','neseparatrixfromfit10^19(m^-3)',\n",
    " 'error_neseparatrixfromfit10^19(m^-3)','FLAG:HRTSdatavalidated']]\n",
    "final_pulse_list = important_info[(important_info['neseparatrixfromexpdata10^19(m^-3)'] != 0.0) & (important_info['neseparatrixfromexpdata10^19(m^-3)'] != -1.0) &  (important_info['shot'] >= 79000) &  (important_info['FLAG:HRTSdatavalidated'] > 0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d47e8662-e546-4bae-81cb-db2fb5503846",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "04eb7bd2-9708-467c-a9c1-4eaf41eb3912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_window_profile_times(profiles, profiles_times, t1, t2):\n",
    "    time_idx = np.logical_and(profiles_times > t1, profiles_times < t2)\n",
    "    return profiles_times[time_idx], profiles[time_idx]\n",
    "\n",
    "def average_machine_with_times(wind_times, mp_values, mp_times): \n",
    "    delta_T = 0.05002594*8\n",
    "    sampled_vals = []\n",
    "    for time in wind_times: \n",
    "        if len(mp_values) == 0:\n",
    "            sampled_vals.append(0.0)\n",
    "            continue\n",
    "        aggregation_idx = np.logical_and(mp_times < time, mp_times > time - delta_T)\n",
    "        aggregation_vals = mp_values[aggregation_idx]\n",
    "        \n",
    "        sampled_vals.append(np.mean(aggregation_vals))\n",
    "    return np.array(sampled_vals)\n",
    "\n",
    "def get_ne_and_te_profiles(raw_shot, t1, t2):\n",
    "    sample_ne = raw_shot['profiles/NE'][:]\n",
    "    sample_te = raw_shot['profiles/TE'][:]\n",
    "    sample_time = raw_shot['profiles/time'][:]\n",
    "    sample_radius = raw_shot['profiles/radius'][:]\n",
    "    \n",
    "    profiles_idx = np.logical_and(sample_time > t1, sample_time < t2)\n",
    "    profiles_ne = sample_ne[profiles_idx]\n",
    "    profiles_te = sample_te[profiles_idx]\n",
    "    if len(profiles_ne[0]) != 63:\n",
    "        profiles_ne = np.pad(profiles_ne, ((0, 0), (0, 63 - len(profiles_ne[0]))), 'constant')\n",
    "    if len(profiles_te[0]) != 63:\n",
    "        profiles_te = np.pad(profiles_te, ((0, 0), (0, 63 - len(profiles_te[0]))), 'constant')\n",
    "    \n",
    "    # Returns to numpy arrays of the same shape\n",
    "    return profiles_ne, profiles_te\n",
    "\n",
    "def combine_ne_te(prof_ne, prof_te):\n",
    "    \n",
    "    combined = np.stack([prof_ne, prof_te], axis=1)\n",
    "    # Want a shape of num_slices X 63\n",
    "    return combined\n",
    "\n",
    "def sample_input(mp_loc, key, t1, t2, window_times): \n",
    "    # print(key)\n",
    "    mp_val, mp_time = mp_loc[key]['values'][:], mp_loc[key]['time'][:]\n",
    "    final_mp_vals = average_machine_with_times(window_times, mp_val, mp_time)\n",
    "    # print(final_mp_vals)\n",
    "    assert len(window_times) == len(final_mp_vals)\n",
    "    return np.array(final_mp_vals)\n",
    "\n",
    "def sample_slices(slices, y):\n",
    "    num_windows = len(slices)\n",
    "        \n",
    "    test_size = int(0.2*num_windows)\n",
    "    val_size = int(0.1*num_windows)\n",
    "    \n",
    "    if val_size == 0 or test_size==0:\n",
    "        val_size = 1\n",
    "        test_size = 1\n",
    "        \n",
    "    train_size = num_windows - test_size - val_size\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, train_idx, test_idx =  train_test_split(slices, y, range(len(slices)), test_size=test_size)\n",
    "    X_train, X_val, y_train, y_val, train_idx, val_idx = train_test_split(X_train, y_train, range(len(X_train)), test_size=val_size)\n",
    "    \n",
    "    return X_train, X_test, X_val, y_train, y_test, y_val, train_idx, val_idx, test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322ddf61-fd3a-48de-b6a7-dcdc0061ac0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_str, y_train_str = [], []\n",
    "X_val_str, y_val_str = [], []\n",
    "X_test_str, y_test_str = [], []\n",
    "\n",
    "X_train_both, y_train_both = [], []\n",
    "X_val_both, y_val_both = [], []\n",
    "X_test_both, y_test_both = [], []\n",
    "\n",
    "radius_train_str = []\n",
    "radius_val_str = []\n",
    "radius_test_str = []\n",
    "radius_train_both = []\n",
    "radius_val_both = []\n",
    "radius_test_both = []\n",
    "i = 0\n",
    "pulse_list = []\n",
    "label_dict = {'BT': '$B_T$ [T]', 'CR0': 'a [m]', 'ELER': '$\\Gamma \\; (10^{22}$ e/s)', 'ELON': '$\\kappa$ [-]', 'POHM': '$P_{OHM}$ [MW]', 'P_ICRH': '$P_{ICRH}$ [MW]', 'P_NBI': '$P_{NBI}$ [MW]', 'Q95' :'$q_{95}$ [-]', 'RGEO': '$R_{geo}$ [m]', 'TRIL': '$\\delta_L$', 'TRIU': '$\\delta_U$', 'VOLM': '$V_P$ [m$^{-3}$]', 'XIP': '$I_P$ [MA]'}\n",
    "with h5py.File('/home/adam/ENR_Sven/moxie/data/processed/profile_database_v1_psi22.hdf5', 'r') as f:\n",
    "    mp_keys = list(label_dict.keys())\n",
    "    print(mp_keys)\n",
    "    for index, row in final_pulse_list.iterrows():\n",
    "        shot, t1, t2 = str(int(row['shot'])), row['t1'], row['t2']\n",
    "        if shot == '79499':\n",
    "            continue\n",
    "        nesep, dnesep = row['neseparatrixfromexpdata10^19(m^-3)'], row['error_neseparatrixfromexpdata10^19(m^-3)']\n",
    "        pulse_sample = f[shot]\n",
    "        pulse_list.append(shot)\n",
    "        \n",
    "        sample_mp = pulse_sample['machine_parameters']\n",
    "        sample_prof = pulse_sample['profiles']\n",
    "        prof_times = sample_prof['time'][:]\n",
    "        profiles = sample_prof['NE'][:]\n",
    "        radii = sample_prof['radius'][:]\n",
    "        \n",
    "        # print(len(sample_mp['ELER/values'][:]))\n",
    "        \n",
    "        window_times, windowed_profiles = get_window_profile_times(profiles, prof_times, t1, t2)\n",
    "        \n",
    "        # Get profiles\n",
    "        profiles_ne, profiles_te = get_ne_and_te_profiles(pulse_sample, t1, t2)\n",
    "        combined = combine_ne_te(profiles_ne, profiles_te)\n",
    "        assert len(profiles_ne) == len(window_times)\n",
    "        \n",
    "        # Get machine parameters\n",
    "        sampled_machine_params = np.array([sample_input(sample_mp, key, t1, t2, window_times) for key in mp_keys]).T\n",
    "        assert len(sampled_machine_params) == len(profiles_ne)\n",
    "        # print(sampled_machine_params)\n",
    "        # print(np.isnan(sampled_machine_params).any())\n",
    "        if np.isnan(sampled_machine_params).any() == True:\n",
    "            if np.isnan(sampled_machine_params[:, 5]).any() == True: \n",
    "                print('Its the ICRH')\n",
    "                np.nan_to_num(sampled_machine_params, copy=False)\n",
    "            print(sampled_machine_params)\n",
    "        assert np.isnan(sampled_machine_params).any() == False\n",
    "        \n",
    "        \n",
    "        ne_train, ne_test, ne_valid, ne_y_train, ne_y_test, ne_y_val, train_idx, val_idx, test_idx = sample_slices(profiles_ne, sampled_machine_params)\n",
    "        \n",
    "        both_train, both_test, both_valid, both_y_train, both_y_test, both_y_val, both_train_idx, both_val_idx, both_test_idx = sample_slices(combined, sampled_machine_params)\n",
    "        \n",
    "        \n",
    "        \n",
    "        X_train_str.extend(ne_train)\n",
    "        X_val_str.extend(ne_valid)\n",
    "        X_test_str.extend(ne_test)\n",
    "        y_train_str.extend(ne_y_train)\n",
    "        y_val_str.extend(ne_y_val)\n",
    "        y_test_str.extend(ne_y_test)\n",
    "\n",
    "\n",
    "        X_train_both.extend(both_train)\n",
    "        X_val_both.extend(both_valid)\n",
    "        X_test_both.extend(both_test)\n",
    "        y_train_both.extend(both_y_train)\n",
    "        y_val_both.extend(both_y_val)\n",
    "        y_test_both.extend(both_y_test)\n",
    "        \n",
    "        radius_train_str.extend([radii for _ in range(len(ne_train))])\n",
    "        radius_val_str.extend([radii for _ in range(len(ne_valid))])\n",
    "        radius_test_str.extend([radii for _ in range(len(ne_test))])\n",
    "        radius_train_both.extend([radii for _ in range(len(both_train))])\n",
    "        radius_val_both.extend([radii for _ in range(len(both_valid))])\n",
    "        radius_test_both.extend([radii for _ in range(len(both_test))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3217c82-8ee7-4a73-9bd6-6db71ad0cd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train_str), len(y_train_str))\n",
    "print(pulse_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d8057db7-7119-4683-a2fd-13d78688bafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('/home/adam/ENR_Sven/moxie/data/processed/profile_database_v1_psi22.hdf5', 'r+') as f:\n",
    "    grp_datasets = f['processed_datasets']\n",
    "    grp_psi = grp_datasets['PSI22']\n",
    "    \n",
    "    del grp_psi['density_revised']\n",
    "    del grp_psi['density_and_temperature_revised']\n",
    "    \n",
    "    grp_strohman = grp_psi.create_group(\"density_revised\")\n",
    "    grp_both = grp_psi.create_group(\"density_and_temperature_revised\")\n",
    "    \n",
    "    grp_str_train = grp_strohman.create_group('train')\n",
    "    grp_str_test = grp_strohman.create_group('test')\n",
    "    grp_str_val = grp_strohman.create_group('valid')\n",
    "\n",
    "    grp_both_train = grp_both.create_group('train')\n",
    "    grp_both_test = grp_both.create_group('test')\n",
    "    grp_both_val = grp_both.create_group('valid')\n",
    "    \n",
    "    meta_group = grp_strohman.create_group(\"meta\")\n",
    "    \n",
    "    \n",
    "    pulse_list = np.array(list(set([int(key) for key in pulse_list])))\n",
    "    key_list = np.array([s.encode('utf-8') for s in mp_keys])\n",
    "    meta_pulse = meta_group.create_dataset('pulse_list', data=pulse_list)\n",
    "    meta_y_atrr = meta_group.create_dataset('y_column_names', data=key_list)\n",
    "\n",
    "    dset_X_train_str = grp_str_train.create_dataset(\"X\", data=X_train_str)\n",
    "    dset_y_train_str = grp_str_train.create_dataset(\"y\", data=y_train_str)\n",
    "    # dset_r_train_str = grp_str_train.create_dataset(\"radii\", data=radius_train_str)\n",
    "\n",
    "    dset_X_test_str = grp_str_test.create_dataset(\"X\", data=X_test_str)\n",
    "    dset_y_test_str = grp_str_test.create_dataset(\"y\", data=y_test_str)\n",
    "    # dset_r_test_str = grp_str_test.create_dataset(\"radii\", data=radius_test_str)\n",
    "\n",
    "    dset_X_val_str = grp_str_val.create_dataset(\"X\", data=X_val_str)\n",
    "    dset_y_val_str = grp_str_val.create_dataset(\"y\", data=y_val_str)\n",
    "    # dset_r_val_str = grp_str_val.create_dataset(\"radii\", data=radius_val_str)\n",
    "\n",
    "\n",
    "    dset_X_train_both = grp_both_train.create_dataset(\"X\", data=X_train_both)\n",
    "    dset_y_train_both = grp_both_train.create_dataset(\"y\", data=y_train_both)\n",
    "    # dset_r_train_both = grp_both_train.create_dataset(\"radii\", data=radius_train_both)\n",
    "        \n",
    "    dset_X_test_both = grp_both_test.create_dataset(\"X\", data=X_test_both)\n",
    "    dset_y_test_both = grp_both_test.create_dataset(\"y\", data=y_test_both)\n",
    "    # dset_r_test_both = grp_both_test.create_dataset(\"radii\", data=radius_test_both)\n",
    "    \n",
    "    dset_X_val_both = grp_both_val.create_dataset(\"X\", data=X_val_both)\n",
    "    dset_y_val_both = grp_both_val.create_dataset(\"y\", data=y_val_both)\n",
    "    # dset_r_val_both = grp_both_val.create_dataset(\"radii\", data=radius_val_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e1ecb8-52fa-4468-910c-51713a7c014f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779406e9-80a8-40b6-a601-d60881804d34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
